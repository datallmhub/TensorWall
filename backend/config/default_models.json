{
  "$schema": "./default_models.schema.json",
  "description": "Default LLM models to seed into the database. Edit this file to customize available models.",
  "models": [
    {
      "model_id": "gpt-4o",
      "name": "GPT-4o",
      "description": "Most capable GPT-4 model, multimodal",
      "provider": "openai",
      "provider_model_id": "gpt-4o",
      "context_length": 128000,
      "supports_vision": true,
      "supports_functions": true,
      "input_cost_per_million": 2.5,
      "output_cost_per_million": 10.0,
      "display_order": 10
    },
    {
      "model_id": "gpt-4o-mini",
      "name": "GPT-4o Mini",
      "description": "Fast and affordable GPT-4",
      "provider": "openai",
      "provider_model_id": "gpt-4o-mini",
      "context_length": 128000,
      "supports_vision": true,
      "supports_functions": true,
      "input_cost_per_million": 0.15,
      "output_cost_per_million": 0.6,
      "display_order": 11
    },
    {
      "model_id": "gpt-4-turbo",
      "name": "GPT-4 Turbo",
      "description": "GPT-4 Turbo with vision",
      "provider": "openai",
      "provider_model_id": "gpt-4-turbo",
      "context_length": 128000,
      "supports_vision": true,
      "supports_functions": true,
      "input_cost_per_million": 10.0,
      "output_cost_per_million": 30.0,
      "display_order": 12
    },
    {
      "model_id": "gpt-3.5-turbo",
      "name": "GPT-3.5 Turbo",
      "description": "Fast, affordable model",
      "provider": "openai",
      "provider_model_id": "gpt-3.5-turbo",
      "context_length": 16385,
      "supports_functions": true,
      "input_cost_per_million": 0.5,
      "output_cost_per_million": 1.5,
      "display_order": 13
    },
    {
      "model_id": "o1",
      "name": "o1",
      "description": "Reasoning model for complex tasks",
      "provider": "openai",
      "provider_model_id": "o1",
      "context_length": 200000,
      "input_cost_per_million": 15.0,
      "output_cost_per_million": 60.0,
      "display_order": 14
    },
    {
      "model_id": "o1-mini",
      "name": "o1-mini",
      "description": "Fast reasoning model",
      "provider": "openai",
      "provider_model_id": "o1-mini",
      "context_length": 128000,
      "input_cost_per_million": 3.0,
      "output_cost_per_million": 12.0,
      "display_order": 15
    },
    {
      "model_id": "claude-3-5-sonnet-20241022",
      "name": "Claude 3.5 Sonnet",
      "description": "Most intelligent Claude model",
      "provider": "anthropic",
      "provider_model_id": "claude-3-5-sonnet-20241022",
      "context_length": 200000,
      "supports_vision": true,
      "input_cost_per_million": 3.0,
      "output_cost_per_million": 15.0,
      "display_order": 20
    },
    {
      "model_id": "claude-3-5-haiku-20241022",
      "name": "Claude 3.5 Haiku",
      "description": "Fast and cost-effective",
      "provider": "anthropic",
      "provider_model_id": "claude-3-5-haiku-20241022",
      "context_length": 200000,
      "supports_vision": true,
      "input_cost_per_million": 1.0,
      "output_cost_per_million": 5.0,
      "display_order": 21
    },
    {
      "model_id": "claude-3-opus-20240229",
      "name": "Claude 3 Opus",
      "description": "Powerful for complex tasks",
      "provider": "anthropic",
      "provider_model_id": "claude-3-opus-20240229",
      "context_length": 200000,
      "supports_vision": true,
      "input_cost_per_million": 15.0,
      "output_cost_per_million": 75.0,
      "display_order": 22
    },
    {
      "model_id": "mistral-large-latest",
      "name": "Mistral Large",
      "description": "Most powerful Mistral model",
      "provider": "mistral",
      "provider_model_id": "mistral-large-latest",
      "base_url": "https://api.mistral.ai/v1",
      "context_length": 128000,
      "supports_functions": true,
      "input_cost_per_million": 2.0,
      "output_cost_per_million": 6.0,
      "display_order": 30
    },
    {
      "model_id": "mistral-small-latest",
      "name": "Mistral Small",
      "description": "Fast and efficient",
      "provider": "mistral",
      "provider_model_id": "mistral-small-latest",
      "base_url": "https://api.mistral.ai/v1",
      "context_length": 128000,
      "supports_functions": true,
      "input_cost_per_million": 0.2,
      "output_cost_per_million": 0.6,
      "display_order": 31
    },
    {
      "model_id": "codestral-latest",
      "name": "Codestral",
      "description": "Specialized for code generation",
      "provider": "mistral",
      "provider_model_id": "codestral-latest",
      "base_url": "https://api.mistral.ai/v1",
      "context_length": 32000,
      "supports_functions": true,
      "input_cost_per_million": 0.2,
      "output_cost_per_million": 0.6,
      "display_order": 32
    },
    {
      "model_id": "pixtral-large-latest",
      "name": "Pixtral Large",
      "description": "Mistral vision model",
      "provider": "mistral",
      "provider_model_id": "pixtral-large-latest",
      "base_url": "https://api.mistral.ai/v1",
      "context_length": 128000,
      "supports_vision": true,
      "input_cost_per_million": 2.0,
      "output_cost_per_million": 6.0,
      "display_order": 33
    },
    {
      "model_id": "gemini-2.0-flash",
      "name": "Gemini 2.0 Flash",
      "description": "Fast multimodal model",
      "provider": "google",
      "provider_model_id": "gemini-2.0-flash-exp",
      "base_url": "https://generativelanguage.googleapis.com/v1beta/openai",
      "context_length": 1000000,
      "supports_vision": true,
      "supports_functions": true,
      "input_cost_per_million": 0.075,
      "output_cost_per_million": 0.3,
      "display_order": 40
    },
    {
      "model_id": "gemini-1.5-pro",
      "name": "Gemini 1.5 Pro",
      "description": "Long context multimodal",
      "provider": "google",
      "provider_model_id": "gemini-1.5-pro",
      "base_url": "https://generativelanguage.googleapis.com/v1beta/openai",
      "context_length": 2000000,
      "supports_vision": true,
      "supports_functions": true,
      "input_cost_per_million": 1.25,
      "output_cost_per_million": 5.0,
      "display_order": 41
    },
    {
      "model_id": "groq/llama-3.3-70b",
      "name": "Llama 3.3 70B (Groq)",
      "description": "Ultra-fast inference via Groq",
      "provider": "groq",
      "provider_model_id": "llama-3.3-70b-versatile",
      "base_url": "https://api.groq.com/openai/v1",
      "context_length": 128000,
      "supports_functions": true,
      "input_cost_per_million": 0.59,
      "output_cost_per_million": 0.79,
      "display_order": 50
    },
    {
      "model_id": "groq/mixtral-8x7b",
      "name": "Mixtral 8x7B (Groq)",
      "description": "Fast MoE model via Groq",
      "provider": "groq",
      "provider_model_id": "mixtral-8x7b-32768",
      "base_url": "https://api.groq.com/openai/v1",
      "context_length": 32768,
      "input_cost_per_million": 0.24,
      "output_cost_per_million": 0.24,
      "display_order": 51
    },
    {
      "model_id": "deepseek-chat",
      "name": "DeepSeek V3",
      "description": "Powerful open-weight model",
      "provider": "deepseek",
      "provider_model_id": "deepseek-chat",
      "base_url": "https://api.deepseek.com/v1",
      "context_length": 64000,
      "supports_functions": true,
      "input_cost_per_million": 0.14,
      "output_cost_per_million": 0.28,
      "display_order": 60
    },
    {
      "model_id": "deepseek-reasoner",
      "name": "DeepSeek R1",
      "description": "Reasoning model",
      "provider": "deepseek",
      "provider_model_id": "deepseek-reasoner",
      "base_url": "https://api.deepseek.com/v1",
      "context_length": 64000,
      "input_cost_per_million": 0.55,
      "output_cost_per_million": 2.19,
      "display_order": 61
    },
    {
      "model_id": "bedrock/claude-3-5-sonnet",
      "name": "Claude 3.5 Sonnet (Bedrock)",
      "description": "Claude via AWS Bedrock",
      "provider": "aws_bedrock",
      "provider_model_id": "anthropic.claude-3-5-sonnet-20241022-v2:0",
      "context_length": 200000,
      "supports_vision": true,
      "input_cost_per_million": 3.0,
      "output_cost_per_million": 15.0,
      "display_order": 70
    },
    {
      "model_id": "bedrock/claude-3-5-haiku",
      "name": "Claude 3.5 Haiku (Bedrock)",
      "description": "Fast Claude via AWS Bedrock",
      "provider": "aws_bedrock",
      "provider_model_id": "anthropic.claude-3-5-haiku-20241022-v1:0",
      "context_length": 200000,
      "supports_vision": true,
      "input_cost_per_million": 1.0,
      "output_cost_per_million": 5.0,
      "display_order": 71
    },
    {
      "model_id": "bedrock/llama-3-2-90b",
      "name": "Llama 3.2 90B (Bedrock)",
      "description": "Meta Llama via AWS Bedrock",
      "provider": "aws_bedrock",
      "provider_model_id": "meta.llama3-2-90b-instruct-v1:0",
      "context_length": 128000,
      "supports_vision": true,
      "input_cost_per_million": 2.0,
      "output_cost_per_million": 2.0,
      "display_order": 72
    },
    {
      "model_id": "bedrock/mistral-large",
      "name": "Mistral Large (Bedrock)",
      "description": "Mistral via AWS Bedrock",
      "provider": "aws_bedrock",
      "provider_model_id": "mistral.mistral-large-2407-v1:0",
      "context_length": 128000,
      "supports_functions": true,
      "input_cost_per_million": 2.0,
      "output_cost_per_million": 6.0,
      "display_order": 73
    },
    {
      "model_id": "bedrock/amazon-nova-pro",
      "name": "Amazon Nova Pro (Bedrock)",
      "description": "Amazon's flagship model",
      "provider": "aws_bedrock",
      "provider_model_id": "amazon.nova-pro-v1:0",
      "context_length": 300000,
      "supports_vision": true,
      "input_cost_per_million": 0.8,
      "output_cost_per_million": 3.2,
      "display_order": 74
    },
    {
      "model_id": "grok-2",
      "name": "Grok 2",
      "description": "xAI's most capable model",
      "provider": "xai",
      "provider_model_id": "grok-2-latest",
      "base_url": "https://api.x.ai/v1",
      "context_length": 131072,
      "supports_vision": true,
      "supports_functions": true,
      "input_cost_per_million": 2.0,
      "output_cost_per_million": 10.0,
      "display_order": 80
    },
    {
      "model_id": "grok-2-mini",
      "name": "Grok 2 Mini",
      "description": "Fast and efficient Grok",
      "provider": "xai",
      "provider_model_id": "grok-2-vision-1212",
      "base_url": "https://api.x.ai/v1",
      "context_length": 32768,
      "supports_vision": true,
      "input_cost_per_million": 0.2,
      "output_cost_per_million": 1.0,
      "display_order": 81
    }
  ]
}
